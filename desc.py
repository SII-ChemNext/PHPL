import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors
import sys,os

# =============================================================================
# --- ç”¨æˆ·é…ç½®åŒºåŸŸ ---
# =============================================================================

# 1. ã€å¿…é¡»ä¿®æ”¹ã€‘è¾“å…¥æ‚¨çš„åŸå§‹CSVæ–‡ä»¶è·¯å¾„
INPUT_CSV_PATH = 'dataset_new/cl_train/raw/cl_train.csv' 

# 2. ã€å»ºè®®ä¿®æ”¹ã€‘è¾“å‡ºæ–‡ä»¶çš„è·¯å¾„
OUTPUT_CSV_PATH = 'dataset_new_desc/cl_train/raw/cl_train.csv' 

# 3. ã€å¿…é¡»ä¿®æ”¹ã€‘æ‚¨çš„æ–‡ä»¶ä¸­åŒ…å«SMILESçš„åˆ—çš„å‡†ç¡®åç§°
SMILES_COL = 'smiles'

# 4. (å¯é€‰) æ¸…æ´—é˜ˆå€¼
#    å¦‚æœä¸€ä¸ªæè¿°ç¬¦åœ¨è¶…è¿‡5%çš„åˆ†å­ä¸­è®¡ç®—å¤±è´¥(NaN, inf, æˆ–è¶…å¤§å€¼)ï¼Œå°±åˆ é™¤è¿™ä¸ªæè¿°ç¬¦åˆ—
BAD_DESCRIPTOR_THRESHOLD = 0.05 
#    å®šä¹‰â€œè¶…å¤§å€¼â€çš„åˆ¤æ–­é˜ˆå€¼ (é€šå¸¸ä¸éœ€è¦ä¿®æ”¹)
LARGE_VALUE_THRESHOLD = 1e6

# =============================================================================
# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---
# =============================================================================

def calculate_rdkit_descriptors(smiles_series):
    """ä¸ºä¸€ä¸ªåŒ…å«SMILESçš„Pandas Seriesè®¡ç®—RDKit 2Dæè¿°ç¬¦ã€‚"""
    print("--> æ­¥éª¤ 2/5: å¼€å§‹è®¡ç®—RDKitæè¿°ç¬¦...")
    descriptor_names = [desc[0] for desc in Descriptors._descList]
    descriptors_list = []
    for smi in smiles_series:
        mol = Chem.MolFromSmiles(smi)
        if mol is None:
            descriptors_list.append([np.nan] * len(descriptor_names))
        else:
            descriptors = [desc_func(mol) for _, desc_func in Descriptors._descList]
            descriptors_list.append(descriptors)
    print(f"    æè¿°ç¬¦è®¡ç®—å®Œæˆã€‚")
    return pd.DataFrame(descriptors_list, columns=descriptor_names, index=smiles_series.index)


def run_preprocessing_pipeline():
    """æ‰§è¡Œå®Œæ•´çš„æ•°æ®åŠ è½½ã€è®¡ç®—ã€æ¸…æ´—å’Œä¿å­˜æµç¨‹ã€‚"""
    
    # 1. åŠ è½½åŸå§‹æ•°æ®
    print(f"--> æ­¥éª¤ 1/5: å¼€å§‹åŠ è½½åŸå§‹æ•°æ®æ–‡ä»¶: '{INPUT_CSV_PATH}'")
    try:
        df_original = pd.read_csv(INPUT_CSV_PATH)
        original_shape = df_original.shape
        print(f"    æˆåŠŸåŠ è½½æ•°æ®ã€‚åŸå§‹æ•°æ®åŒ…å« {original_shape[0]} è¡Œ, {original_shape[1]} åˆ—ã€‚")
    except FileNotFoundError:
        print(f"    [é”™è¯¯] æ‰¾ä¸åˆ°æ–‡ä»¶ '{INPUT_CSV_PATH}'ã€‚")
        sys.exit()

    if SMILES_COL not in df_original.columns:
        print(f"    [é”™è¯¯] åœ¨CSVæ–‡ä»¶ä¸­æ‰¾ä¸åˆ°æŒ‡å®šçš„SMILESåˆ— '{SMILES_COL}'ã€‚")
        sys.exit()

    # 2. è®¡ç®—æè¿°ç¬¦
    df_descriptors = calculate_rdkit_descriptors(df_original[SMILES_COL])

    # 3. åˆå¹¶æ•°æ®
    print("--> æ­¥éª¤ 3/5: åˆå¹¶åŸå§‹æ•°æ®å’Œæè¿°ç¬¦...")
    df_processed = pd.concat([df_original, df_descriptors], axis=1)
    print("    æ•°æ®åˆå¹¶å®Œæˆã€‚")
    df_processed=df_processed.drop(columns=['Ipc'])
    # 4. æ‰§è¡ŒåŒ…å«â€œè¶…å¤§å€¼â€æ£€æµ‹çš„æœ€ç»ˆæ¸…æ´—æµç¨‹
    print("--> æ­¥éª¤ 4/5: å¼€å§‹æ‰§è¡Œæœ€ç»ˆæ•°æ®æ¸…æ´—æµç¨‹...")
    
    # =============================================================================
    # â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼  ã€æœ€ç»ˆç‰ˆæ¸…æ´—é€»è¾‘ã€‘  â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
    # =============================================================================
    # 4.1 ç»Ÿä¸€é—®é¢˜ï¼šå°†infå’Œè¶…å¤§å€¼å…¨éƒ¨è½¬æ¢ä¸ºNaN
    
    # ç­›é€‰å‡ºæ•°å€¼ç±»å‹çš„åˆ—è¿›è¡Œæ“ä½œ
    numeric_cols = df_processed.select_dtypes(include=np.number).columns
    
    # æ›¿æ¢æ— ç©·å¤§å€¼
    df_processed[numeric_cols] = df_processed[numeric_cols].replace([np.inf, -np.inf], np.nan)
    print("    [æ¸…æ´—-0] å·²å°†æ‰€æœ‰ inf å€¼æ›¿æ¢ä¸º NaNã€‚")
    
    # æ›¿æ¢è¶…å¤§å€¼
    # åˆ›å»ºä¸€ä¸ªå¸ƒå°”æ©ç ï¼Œæ ‡è®°æ‰€æœ‰ç»å¯¹å€¼è¶…è¿‡é˜ˆå€¼çš„ä½ç½®
    mask_large_values = (df_processed[numeric_cols].abs() > LARGE_VALUE_THRESHOLD)
    # å°†è¿™äº›ä½ç½®çš„å€¼è®¾ä¸ºNaN
    df_processed[mask_large_values] = np.nan
    print("    [æ¸…æ´—-0] å·²å°†æ‰€æœ‰è¶…å¤§å€¼æ›¿æ¢ä¸º NaNã€‚")

    # 4.2 ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«å¹¶åˆ é™¤â€œåâ€çš„æè¿°ç¬¦ï¼ˆåˆ—ï¼‰
    # ç°åœ¨æ‰€æœ‰çš„åæ•°æ®ç‚¹éƒ½æ˜¯NaNäº†ï¼Œé€»è¾‘å˜å¾—ç®€å•
    missing_ratios = df_processed.isnull().sum() / len(df_processed)
    bad_cols = missing_ratios[missing_ratios > BAD_DESCRIPTOR_THRESHOLD].index.tolist()
    
    # ä»å¾…åˆ é™¤åˆ—è¡¨ä¸­ç§»é™¤åŸå§‹æ•°æ®ä¸­çš„åˆ—ï¼Œä»¥é˜²ä¸‡ä¸€
    original_cols_to_keep = df_original.columns.tolist()
    bad_cols = [col for col in bad_cols if col not in original_cols_to_keep]

    if bad_cols:
        print(f"    [æ¸…æ´—-1] å‘ç° {len(bad_cols)} ä¸ªæè¿°ç¬¦åˆ—å› åŒ…å«è¿‡å¤šæ— æ•ˆå€¼(NaN/inf/è¶…å¤§å€¼)å°†è¢«åˆ é™¤:")
        print(f"      {bad_cols}")
        df_processed.drop(columns=bad_cols, inplace=True)
    else:
        print("    [æ¸…æ´—-1] æœªå‘ç°éœ€è¦åˆ é™¤çš„â€˜åâ€™æè¿°ç¬¦åˆ—ã€‚")

    # 4.3 ç¬¬äºŒæ­¥ï¼šåˆ é™¤å‰©ä½™åŒ…å«é›¶æ˜ŸNaNçš„åˆ†å­ï¼ˆè¡Œï¼‰
    initial_rows = len(df_processed)
    df_processed.dropna(inplace=True)
    final_rows = len(df_processed)
    
    print(f"    [æ¸…æ´—-2] ç§»é™¤äº† {initial_rows - final_rows} ä¸ªåŒ…å«é›¶æ˜Ÿæ— æ•ˆå€¼çš„åˆ†å­ï¼ˆè¡Œï¼‰ã€‚")
    print("    æ•°æ®æ¸…æ´—å®Œæˆã€‚")
    # =============================================================================
    # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²  ã€æ¸…æ´—ç»“æŸã€‘  â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²
    # =============================================================================

    # 5. ä¿å­˜æœ€ç»ˆç»“æœ
    print(f"--> æ­¥éª¤ 5/5: ä¿å­˜æ¸…ç†åçš„æ•°æ®åˆ° '{OUTPUT_CSV_PATH}'")
    try:
        dir = os.path.dirname(OUTPUT_CSV_PATH)
        os.makedirs(dir, exist_ok=True)
        df_processed.to_csv(OUTPUT_CSV_PATH, index=False)
        final_shape = df_processed.shape
        print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
        print(f"    åŸå§‹æ•°æ®å°ºå¯¸: {original_shape[0]} è¡Œ x {original_shape[1]} åˆ—")
        print(f"    æœ€ç»ˆè¾“å‡ºå°ºå¯¸: {final_shape[0]} è¡Œ x {final_shape[1]} åˆ—")
        print(f"    ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_CSV_PATH}")
    except Exception as e:
        print(f"    [é”™è¯¯] ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

# =============================================================================
# --- è„šæœ¬æ‰§è¡Œå…¥å£ ---
# =============================================================================
if __name__ == "__main__":
    run_preprocessing_pipeline()
